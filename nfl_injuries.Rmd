---
title: "NFL Injuries"
author: "Peter Walsh"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    code_download: TRUE
    number_sections: TRUE
    paged_df: TRUE
    toc: TRUE
    toc_float: TRUE
    theme: readable
---
NFL Injures


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      progress = FALSE,
                      verbose = TRUE,
                      cache = TRUE)

```

## Required R Packages
```{r}
if(require(pacman)== FALSE) install.packages("pacman")
pacman::p_load(tidyverse, 
               tidycensus, # for getting the census data
               httr, jsonlite, # pkgs that we might use for API,
               janitor,
               lubridate,# for making a column name from row 1
               magrittr, rvest, nflreadr, nflfastR, reticulate, geosphere)
```

## Required Python Packages
```{r }
reticulate::py_install('bs4')
reticulate::py_install('pandas')
reticulate::py_install('lxml')
reticulate::py_install('requests')

```

---

## Importing NFL Schedule from 2019 to 2023 and Adding Home and Away Columns to the Dataframe

```{python complete_game_schedule_2019_23}
from bs4 import BeautifulSoup
import pandas as pd
import requests
import lxml.html as lh

# Loop through years 2019 to 2022
for year in range(2019, 2023):
    url_scores = f'https://www.pro-football-reference.com/years/{year}/games.htm'
    # Create object page
    page = requests.get(url_scores)
    doc = lh.fromstring(page.content)
    # Parse data that are stored between <tr>..</tr> of HTML
    tr_elements = doc.xpath('//table[@id="games"]/tbody/tr')

    # Extract required columns by their index
    required_columns = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]

    # Create empty list to hold the rows of data
    data_rows = []

    # Process game data for each row
    for j in range(len(tr_elements)):
        T = tr_elements[j]
        # Check if row is a game row
        if len(T) == 14:
            # Iterate through each element of the row
            row_data = []
            for i in required_columns:
                data = T[i].text_content().strip()
                # Convert numerical values to integers
                if i in (7, 8, 9, 10, 11, 12, 13):
                    try:
                        data = int(data)
                    except:
                        pass
                # Append the data to the row list
                row_data.append(data)
            # Append the row to the data list
            data_rows.append(row_data)

    # Create a Pandas DataFrame from the processed data
    df_scores = pd.DataFrame(data_rows, columns=['week', 'day', 'date', 'time', 'winner/tie', 'at', 'loser/tie', 'boxscore', 'pts_w', 'pts_l', 'yds_w', 'tov_w', 'yds_l', 'tov_l'])

    # Add a season column with the year value
    df_scores['season'] = year

    # Append the DataFrame to a master DataFrame
    if year == 2019:
        df_master = df_scores
    else:
        df_master = pd.concat([df_master, df_scores], ignore_index=True)

def is_home_team(row):
  matchup = row["at"]
  winner_name = row['winner/tie']
  loser_name = row['loser/tie']
  if "@" in matchup:
    #home_team == loser_name
    home_team = loser_name
    return home_team == loser_name
  
  else:
    return False

# Apply the custom function to each row of the DataFrame
df_master["loser_is_home"] = df_master.apply(lambda row: is_home_team(row), axis=1)

df_master.drop(['at', 'boxscore'], axis = 1, inplace = True)
df_master = df_master[df_master["week"] != "Week"]
df_master = df_master[df_master["date"] != "Playoffs"]

## had to make changes to the "week" values that were strings: "WildCard", "Division", "ConfChamp", "SuperBowl"
df_master.to_csv("df_master_playoff_week_fix.csv", index = False)

## updated name of csv to make sure its not over written
df_master_updated = pd.read_csv("Rmd_files/df_master_playoff_week_fix1.csv")


# Create empty lists for home and away teams
home_teams = []
away_teams = []

# Iterate over each row of the DataFrame
for index, row in df_master.iterrows():
    # Check if loser is home
    if row['loser_is_home'] == True:
        home_team = row['loser/tie']
        away_team = row['winner/tie']
    else:
        home_team = row['winner/tie']
        away_team = row['loser/tie']
    # Append home and away teams to the lists
    home_teams.append(home_team)
    away_teams.append(away_team)

# Add the new columns to the DataFrame
df_master_updated['Home_Team'] = home_teams
df_master_updated['Away_Team'] = away_teams

pd.set_option('display.max_columns', 50)
#df_master_updated
team_abbr = {
    'Arizona Cardinals': 'ARI',
    'Atlanta Falcons': 'ATL',
    'Baltimore Ravens': 'BAL',
    'Buffalo Bills': 'BUF',
    'Carolina Panthers': 'CAR',
    'Chicago Bears': 'CHI',
    'Cincinnati Bengals': 'CIN',
    'Cleveland Browns': 'CLE',
    'Dallas Cowboys': 'DAL',
    'Denver Broncos': 'DEN',
    'Detroit Lions': 'DET',
    'Green Bay Packers': 'GB',
    'Houston Texans': 'HOU',
    'Indianapolis Colts': 'IND',
    'Jacksonville Jaguars': 'JAX',
    'Kansas City Chiefs': 'KC',
    'Las Vegas Raiders': 'LV',
    'Los Angeles Chargers': 'LAC',
    'Los Angeles Rams': 'LAR',
    'Miami Dolphins': 'MIA',
    'Minnesota Vikings': 'MIN',
    'New England Patriots': 'NE',
    'New Orleans Saints': 'NO',
    'New York Giants': 'NYG',
    'New York Jets': 'NYJ',
    'Philadelphia Eagles': 'PHI',
    'Pittsburgh Steelers': 'PIT',
    'San Francisco 49ers': 'SF',
    'Seattle Seahawks': 'SEA',
    'Tampa Bay Buccaneers': 'TB',
    'Tennessee Titans': 'TEN',
    'Washington Football Team': 'WAS',
    'Washington Redskins': 'WAS',
    'Washington Commanders': 'WAS',
    'Oakland Raiders': 'OAK'
}
abbr_team = {v: k for k, v in team_abbr.items()}


def get_abbr(team_name):
    return team_abbr.get(team_name)

# Create new columns for home and away team abbreviations
df_master_updated['Home_abbr'] = df_master_updated.apply(lambda row: get_abbr(row['Home_Team']), axis=1)
df_master_updated['Away_abbr'] = df_master_updated.apply(lambda row: get_abbr(row['Away_Team']), axis=1)

# format the "week" column with leading zeros
df_master_updated['week'] = df_master_updated['week'].apply(lambda x: f'0{x}' if x < 10 else str(x))

# Create the new column
df_master_updated['game_id'] = df_master_updated['season'].astype(str) + '_' + df_master_updated['week'].astype(str).str.zfill(2) + '_' + df_master_updated['Away_abbr'] + '_' + df_master_updated['Home_abbr']

# Insert the new column at the beginning of the DataFrame
df_master_updated.insert(0, 'game_id', df_master_updated.pop('game_id'))
# Print the updated DataFrame


df_master_updated.to_csv('Master_Schedule_2019_23_updated_Rmd.csv', index = False)
df_master_updated.head(20)
```


Created a `game_id` variable in order to join with the `injury_plays` table created using `nflfastR`. `game_id` formatted the same was as nflfastR encodes them is as follows: `season`_`week`_`away_abbr`_`home_abbr`. Finally, I had to change the playoff weeks that had names (e.g., WildCard, Division, ConfChamp, SuperBowl) manually because the NFL has changed the playoff format over the past few years.


## Joining the `master_schedule` with the `injury_plays` from the `nflfastR` package 

```{r pbp_injured_players_2019_23}
## this is equivalent to Master_Schedule_2019_23_updated_Rmd but did not want overwritten 
master_schedule = read_csv('Rmd_files/Master_Schedule_2019_23_updated_Rmd1.csv')

start_season = 2019
end_season = 2022

pbp = nflfastR::load_pbp(start_season:end_season)

injury_plays = pbp %>% filter(grepl("injured", desc, ignore.case = TRUE))
injury_plays = injury_plays %>% unique()
injury_plays= injury_plays %>% select(game_id,home_team,away_team,season_type,week ,posteam,posteam_type,defteam,
                                      side_of_field,yardline_100,game_date,quarter_seconds_remaining,half_seconds_remaining,
                                      game_seconds_remaining,game_half,qtr,down, time,yrdln,ydstogo,desc)
injury_plays$injured_player = sub(".*(\\b\\w+\\.\\w+\\b) was injured.*", "\\1", injury_plays$desc)
injury_plays$injured_team = sub(".*(\\b\\w+-\\d+).*(\\b\\w+\\.\\w+\\b) was injured.*", "\\1", injury_plays$desc)


injury_plays = injury_plays %>% distinct()
combined_data = full_join(master_schedule, injury_plays, by = "game_id", multiple = "all")


combined_data %>% group_by(game_id) -> combined_grouped

counter_fun = function(x){
  ifelse(is.na(x), 0, length(x)) %>% unique()
}

combined_grouped %<>% 
  nest() %>%
  mutate(injured_players = map(.x = data, .f = magrittr::extract2, 'injured_player'),
         num_injuries = map_dbl(.x= injured_players, .f = counter_fun))

combined_grouped$injured_players <- ifelse(combined_grouped$injured_players == "NANA", "No Injury", combined_grouped$injured_players)
combined_grouped$injured_players <- ifelse(combined_grouped$injured_players == "NA", "No Injury", combined_grouped$injured_players)

## separates the names to only include player names that got injured during the game
combined_grouped$injured_players <- sapply(combined_grouped$injured_players, function(x) ifelse(is.character(x), paste(sapply(strsplit(x, ", "), function(y) trimws(y)), collapse = ", "), x))

combined_grouped = combined_grouped[,-2]

schedule_injury_2019_23_complete = left_join(master_schedule, combined_grouped, by = "game_id", multiple = 'all')
#write_csv(schedule_injury_2019_23_complete, "schedule_injury_2019_23_complete.csv")
#head(schedule_injury_2019_23_complete,15)

## Adding the number of snaps that took place in a game

play_counts = as.data.frame(table(pbp$game_id))
names(play_counts) = c("game_id", "num_plays")
#play_counts <- play_counts[-c(267, 536, 821, 1105), ]
## Reset index
row.names(play_counts) <- NULL
play_counts <- data.frame(play_counts)

## Main Issue: one data set has the Los Angeles Rams abbreviation as LA and the other dataset has the abbreviation of LAR (71 observations)
# Some lines were not properly reading (duplicate games with all NAs in one duplicate besides the num_plays and other duplicate has all the information and NAs for num_play)
play_counts$game_id <- gsub("(^|_)LA(_|$)", "\\1LAR\\2", play_counts$game_id)
schedule_injury_2019_23_complete = merge(schedule_injury_2019_23_complete, play_counts, by = "game_id")

## Manually changing some of the injury_players because some of them are not formatted in a proper way (i.e., hyphens and spaces in name, different formatting than the rest, etc.)
write_csv(schedule_injury_2019_23_complete, 'schedule_injury_2019_23_complete_upated.csv')

```


## Adding Stadium Name, Surface, Surface_Type, and whether or not the stadium has a dome

```{r adding_surface_stadium_name_and_dome}
## this is equivalent of schedule_injury_2019_23_complete_upated but made new copy to make sure the manual changes to names was not overwritten
schedule_injury_2019_23_complete_updated = read_csv('Rmd_files/schedule_injury_2019_23_complete_upated_Rmd.csv')

# Create a list of dictionaries that maps team abbreviations to the surface, stadium, dome, and surface_type they play on
team_surface <- list(
  ARI = list(surface = "Bermuda Grass", surface_type = "Grass", stadium = "State Farm Stadium", dome = TRUE),
  ATL = list(surface = "FieldTurf Revolution", surface_type = "Turf", stadium = "Mercedes-Benz Stadium", dome = TRUE),
  BAL = list(surface = "Bermuda Grass", surface_type = "Grass", stadium = "M&T Bank Stadium", dome = FALSE),
  BUF = list(surface = "A-Turf Titan", surface_type = "Turf", stadium = "Highmark Stadium", dome = FALSE),
  CAR = list(surface = "Bermuda Grass", surface_type = "Grass", stadium = "Bank of America Stadium", dome = FALSE),
  CHI = list(surface = "Kentucky Bluegrass", surface_type = "Grass", stadium = "Soldier Field", dome = FALSE),
  CIN = list(surface = "UBU Sports Speed S5-M Synthetic Turf", surface_type = "Turf", stadium = "Paul Brown Stadium", dome = FALSE),
  CLE = list(surface = "Kentucky Bluegrass", surface_type = "Grass", stadium = "FirstEnergy Stadium", dome = FALSE),
  DAL = list(surface = "Hellas Matrix Turf", surface_type = "Turf", stadium = "AT&T Stadium", dome = TRUE),
  DEN = list(surface = "Kentucky Bluegrass", surface_type = "Grass", stadium = "Empower Field at Mile High", dome = FALSE),
  DET = list(surface = "FieldTurf Classic HD", surface_type = "Turf", stadium = "Ford Field", dome = TRUE),
  GB = list(surface = "Desso GrassMaster", surface_type = "Hybrid", stadium = "Lambeau Field", dome = FALSE),
  HOU = list(surface = "Hellas Matrix Turf", surface_type = "Turf", stadium = "NRG Stadium", dome = TRUE),
  IND = list(surface = "Shaw Sports Momentum Pro", surface_type = "Turf", stadium = "Lucas Oil Stadium", dome = TRUE),
  JAX = list(surface = "Bermuda Grass", surface_type = "Grass", stadium = "TIAA Bank Field", dome = FALSE),
  KC = list(surface = "Bermuda Grass", surface_type = "Grass", stadium = "Arrowhead Stadium", dome = FALSE),
  LV = list(surface = "Bermuda Grass", surface_type = "Grass", stadium = "Allegiant Stadium", dome = TRUE),
  LAC = list(surface = "Hellas Matrix Turf", surface_type = "Turf", stadium = "SoFi Stadium", dome = TRUE),
  LAR = list(surface = "Hellas Matrix Turf", surface_type = "Turf", stadium = "SoFi Stadium", dome = TRUE),
  MIA = list(surface = "Bermuda Grass", surface_type = "Grass", stadium = "Hard Rock Stadium", dome = TRUE),
  MIN = list(surface = "UBU Sports Speed S5-M", surface_type = "Turf", stadium = "U.S. Bank Stadium", dome = TRUE),
  NE = list(surface = "FieldTurf CORE", surface_type = "Turf", stadium = "Gillette Stadium", dome = FALSE),
  NO = list(surface = "FieldTurf Revolution 360", surface_type = "Turf", stadium = "Caesars Superdome", dome = TRUE),
  NYG = list(surface = "FieldTurf Classic HD", surface_type = "Turf", stadium = "MetLife Stadium", dome = FALSE),
  NYJ = list(surface = "FieldTurf Classic HD", surface_type = "Turf", stadium = "MetLife Stadium", dome = FALSE),
  PHI = list(surface = "Desso GrassMaster", surface_type = "Hybrid", stadium = "Lincoln Financial Field", dome = FALSE),
  PIT = list(surface = "Kentucky Bluegrass", surface_type = "Grass", stadium = "Heinz Field", dome = FALSE),
  SF = list(surface = "Bermuda Grass,Perennial Ryegrass Mixture", surface_type = "Grass", stadium = "Levi's Stadium", dome = FALSE),
  SEA = list(surface = "FieldTurf Revolution 360", surface_type = "Turf", stadium = "Lumen Field", dome = FALSE),
  TB = list(surface = "Bermuda Grass", surface_type = "Grass", stadium = "Raymond James Stadium", dome = FALSE),
  TEN = list(surface = "Bermuda Grass", surface_type = "Grass", stadium = "Nissan Stadium", dome = FALSE),
  WAS = list(surface = "Bermuda Grass", surface_type = "Grass", stadium = "FedExField", dome = FALSE),
  OAK = list(surface = "Bermuda Grass", surface_type = "Grass", stadium = "Oakland Coliseum", dome = FALSE)
)

team_surface_df <- map_df(team_surface, ~.x %>% as_tibble() %>% set_names(c("surface", "surface_type", "stadium", "dome")), .id = "team")

team_surface_df <- team_surface_df %>%
  rename(Home_abbr = team)

library(dplyr)

schedule_injury_2019_23_complete_updated <- schedule_injury_2019_23_complete_updated %>% select(-Home_abbr, everything(), Home_abbr)


df_master_schedule_injury_surface_2019_23 <- schedule_injury_2019_23_complete_updated %>%
  left_join(team_surface_df, by = "Home_abbr")

colSums(is.na(df_master_schedule_injury_surface_2019_23))
## checking to make sure there are no NAs present after merge is complete
write_csv(df_master_schedule_injury_surface_2019_23, 'df_master_schedule_injury_surface_2019_23_Rmd.csv')
head(df_master_schedule_injury_surface_2019_23,20)

df2 = 

```


## Adding Weather Script to `df_master_schedule_injury_surface_2019_23`

```{r adding_weather_to_df_master_above}
pacman::p_load(tidyverse, rvest, stringr)

## this is the equivalent of df_master_schedule_injury_surface_2019_23_Rmd.csv but made copy to make sure it was not overwritten during knitting process
schedule = read.csv('Rmd_files/df_master_schedule_injury_surface_2019_23_no_weather.csv')
schedule$date = schedule$date %>% as.Date(format = "%m/%d/%y")

results <- list()

# loop through each row of the data frame
for (i in 1:nrow(schedule)) {
  # extract the variables for the current row
  season = schedule$season[[i]]
  week = schedule$week[[i]]
  date = schedule$date[[i]]
  away = tail(strsplit(schedule$Away_Team[i], " ")[[1]], 1)
  away = ifelse(away == 'Team' & date >= '2020-09-13' & date <= '2020-09-20', 
                'redskins',
                ifelse(away == 'Team' & date > '2020-09-20' & date <= '2020-11-22', 
                       'football%20team',
                       ifelse(away == 'Team' & date > '2020-11-22' & date <= '2020-12-13',
                              'Washington',
                              ifelse(away == 'Team' & date == '2020-12-20',
                                     'football%20team',
                                     ifelse((away == 'Team' | away == 'Commanders') & date > '2020-12-20',
                                            'Washington',
                                            tail(strsplit(schedule$Away_Team[i], " ")[[1]], 1))))))
  
  home = tail(strsplit(schedule$Home_Team[i], " ")[[1]], 1)
  home = ifelse(home == 'Team' & date >= '2020-09-13' & date <= '2020-09-20', 
                'redskins',
                ifelse(home == 'Team' & date > '2020-09-20' & date <= '2020-11-22', 
                       'football%20team',
                       ifelse(home == 'Team' & date > '2020-11-22' & date <= '2020-12-13',
                              'washington',
                              ifelse(home == 'Team' & date == '2020-12-20',
                                     'football%20team',
                                     ifelse((home == 'Team' | home == 'Commanders') & date > '2020-12-20',
                                            'washington',
                                            tail(strsplit(schedule$Home_Team[i], " ")[[1]], 1))))))
  
  
  # construct the URL and read the HTML
  url = ifelse(week == 'WildCard', 
               paste0('https://www.nflweather.com/game/', season, '/',  week,'-weekend/', away, '-at-', home),
               ifelse(week == 'Division', paste0('https://www.nflweather.com/game/', season, '/',  week,'al-playoffs/', away, '-at-', home),
                      ifelse(week == 'ConfChamp', paste0('https://www.nflweather.com/game/', season, '/%20conf-championships/', away, '-at-', home),
                             ifelse(week == 'SuperBowl' & season == '2021', paste0('https://www.nflweather.com/game/', season, '/',  week, '/', home, '-at-', away),
                                    ifelse(week == 'SuperBowl', paste0('https://www.nflweather.com/game/', season, '/', week, '/', away, '-at-', home),
                                           paste0('https://www.nflweather.com/game/', season, '/week-',  week, '/', away, '-at-', home))))))
  
  read_url <- read_html(url)
  
  # extract the weather data from each quarter
  q1_temp <- html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(1) > p:nth-child(5) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  q2_temp <- html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(2) > p:nth-child(5) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  q3_temp <- html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(3) > p:nth-child(5) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  q4_temp <- html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(4) > p:nth-child(5) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  
  q1_feels_like = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(1) > p:nth-child(6) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  q2_feels_like = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(2) > p:nth-child(6) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  q3_feels_like = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(3) > p:nth-child(6) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  q4_feels_like = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(4) > p:nth-child(6) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  
  
  q1_wind = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(1) > p:nth-child(7) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  q2_wind = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(2) > p:nth-child(7) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  q3_wind = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(3) > p:nth-child(7) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  q4_wind = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(4) > p:nth-child(7) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  
  q1_humidity = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(1) > p:nth-child(8) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  q2_humidity = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(2) > p:nth-child(8) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  q3_humidity = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(3) > p:nth-child(8) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  q4_humidity = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(4) > p:nth-child(8) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  
  q1_percipitation_prob = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(1) > p:nth-child(13) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  q2_percipitation_prob = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(2) > p:nth-child(13) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  q3_percipitation_prob = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(3) > p:nth-child(13) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  q4_percipitation_prob = html_text2(html_elements(read_url, 'body > div > div:nth-child(4) > div > div.span10 > div:nth-child(7) > div:nth-child(4) > p:nth-child(13) > b')) |> 
    str_extract("\\d+") |> 
    as.numeric()
  
  # calculate the average weather data for the game
  avg_temp = mean(c(q1_temp, q2_temp, q3_temp, q4_temp))
  avg_feels_like = mean(c(q1_feels_like, q2_feels_like, q3_feels_like, q4_feels_like))
  avg_wind_mph = mean(c(q1_wind, q2_wind, q3_wind, q4_wind))
  avg_humidity_percent = mean(c(q1_humidity, q2_humidity, q3_humidity, q4_humidity))
  avg_percipitation_prob_percent = mean(c(q1_percipitation_prob, q2_percipitation_prob, q3_percipitation_prob, q4_percipitation_prob))
  
  
  
  # create a data frame with the results for the current row
  result <- data.frame(week, season, date, away, home, avg_temp, avg_feels_like, avg_wind_mph, avg_humidity_percent, avg_percipitation_prob_percent)
  
  # add the data frame to the results list
  results[[i]] = result
}

# combine the results into a single data frame
weather = do.call(rbind, results)

#write.csv(weather, "Game_Weather_2019-23.csv")

schedule = schedule |> 
  dplyr::mutate(
    Avg_Temp = weather$avg_temp,
    Avg_Feels_Like = weather$avg_feels_like,
    Avg_Wind_MPH = weather$avg_wind_mph,
    Avg_Humidity_Percent = weather$avg_humidity_percent,
    Avg_Percipitation_Prob_Percent = weather$avg_percipitation_prob_percent
  )

write.csv(schedule, "df_master_schedule_injury_surface_2019_23_weather.csv")
head(schedule, 20)

```

## Adding Latitude & Longitude based on Distance from Away Team's Stadium to the Home Team's Sta (distance traveled for away games)

```{r}
library(purrr)
df_master_schedule_injury_surface_2019_23_weather = read_csv("Rmd_files/df_master_schedule_injury_surface_2019_23_weather.csv")
nfl_coordinates = read_csv("Rmd_files/NFL_Latitude_Longitude.csv")

nfl_coordinates <- nfl_coordinates %>%
  mutate(team_abbr = case_when(
    Team == "Arizona Cardinals" ~ "ARI",
    Team == "Atlanta Falcons" ~ "ATL",
    Team == "Baltimore Ravens" ~ "BAL",
    Team == "Buffalo Bills" ~ "BUF",
    Team == "Carolina Panthers" ~ "CAR",
    Team == "Chicago Bears" ~ "CHI",
    Team == "Cincinnati Bengals" ~ "CIN",
    Team == "Cleveland Browns" ~ "CLE",
    Team == "Dallas Cowboys" ~ "DAL",
    Team == "Denver Broncos" ~ "DEN",
    Team == "Detroit Lions" ~ "DET",
    Team == "Green Bay Packers" ~ "GB",
    Team == "Houston Texans" ~ "HOU",
    Team == "Indianapolis Colts" ~ "IND",
    Team == "Jacksonville Jaguars" ~ "JAX",
    Team == "Kansas City Chiefs" ~ "KC",
    Team == "Las Vegas Raiders" ~ "LV",
    Team == "Los Angeles Chargers" ~ "LAC",
    Team == "Los Angeles Rams" ~ "LAR",
    Team == "Miami Dolphins" ~ "MIA",
    Team == "Minnesota Vikings" ~ "MIN",
    Team == "New England Patriots" ~ "NE",
    Team == "New Orleans Saints" ~ "NO",
    Team == "New York Giants" ~ "NYG",
    Team == "New York Jets" ~ "NYJ",
    Team == "Philadelphia Eagles" ~ "PHI",
    Team == "Pittsburgh Steelers" ~ "PIT",
    Team == "San Francisco 49ers" ~ "SF",
    Team == "Seattle Seahawks" ~ "SEA",
    Team == "Tampa Bay Buccaneers" ~ "TB",
    Team == "Tennessee Titans" ~ "TEN",
    Team == "Washington Football Team" | Team == "Washington Redskins" | Team == "Washington Commanders" ~ "WAS",
    Team == "Oakland Raiders" ~ "OAK",
    TRUE ~ NA_character_
  ))

library(dplyr)

# Create a lookup table for team abbreviations, latitude, and longitude
team_lookup <- nfl_coordinates %>% 
  select(team_abbr, Latitude, Longitude)

# Join the team_lookup to the master schedule
df_master_surface_coords <- df_master_schedule_injury_surface_2019_23_weather %>%
  left_join(team_lookup, by = c("Home_abbr" = "team_abbr")) %>%
  rename(Home_latitude = Latitude, Home_longitude = Longitude) %>%
  left_join(team_lookup, by = c("Away_abbr" = "team_abbr")) %>%
  rename(Away_latitude = Latitude, Away_longitude = Longitude)

library(geosphere)


df_master_surface_coords$distance_miles <- distHaversine(
  p1 = df_master_surface_coords[, c("Home_longitude", "Home_latitude")],
  p2 = df_master_surface_coords[, c("Away_longitude", "Away_latitude")],
  r = 3959  # Earth radius in miles
)
df_master_surface_coords = df_master_surface_coords[,-1]

write.csv(df_master_surface_coords, "df_master_schedule_injury_surface_2019_23_weather_distance.csv")
## STILL NEED TO CHANGE THE GAMES THAT WERE INTERNATIONAL OR PLAYED AT NEUTRAL SITES (SUPERBOWL)

## ADD BACK THE TWO SUPERBOWL GAMES THAT WERE DROPPED AND ASSOCIATED INJURIES (2019 AND 2020 SB)
head(df_master_surface_coords,20)
```

## Adding Days since both teams played their last game

```{r days_since_last_game_merge}

library(dplyr)

# read in the tables
df_master_surface_coords <- read_csv("df_master_schedule_injury_surface_2019_23_weather_distance.csv")
NFL_Days_Since_Last_Game <- read_csv("NFL_Days_Since_Last_Game.csv")


NFL_Days_Since_Last_Game$date = NFL_Days_Since_Last_Game$date %>% as.Date(format = "%m/%d/%y")

# join the tables
df_master_surface_coords <- df_master_surface_coords %>%
  # join with NFL_Days_Since_Last_Game by home_team, away_team and date_of_game
  left_join(NFL_Days_Since_Last_Game, by = c("Home_Team" = "Home_Team", "Away_Team" = "Away_Team", "date" = "date"))

df_master_surface_coords = df_master_surface_coords[,-38]
head(df_master_surface_coords,20)
write_csv(df_master_surface_coords, "df_master_schedule_injury_surface_2019_23_weather_distance_days_since_last_game.csv")

```

```{r players_missing_games_from_injury}
# Define the URL template
url_template <- "https://www.prosportstransactions.com/football/Search/SearchResults.php?Player=&Team=&BeginDate=2019-09-08&EndDate=2023-01-29&InjuriesChkBx=yes&submit=Search&start=%d"

# Specify the starting value for the start parameter
start_value <- 0

# Initialize an empty data.frame to store the data
games_missed_from_injury <- data.frame()

# Repeat the loop until you have scraped all pages (105 pages)
while (start_value <= 2600) {
  # Define the URL
  url <- sprintf(url_template, start_value)
  
  # Read the HTML content from the URL
  html_content <- read_html(url)
  
  # Extract the table from the HTML content
  table_html <- html_content %>%
    html_node("table") %>%
    html_table()
  
  # Check if the table is empty (no more pages)
  if (nrow(table_html) == 0) {
    break
  }
  
  # Specify the column names
  colnames(table_html) <- c("Date", "Team","Acquired" ,"Relinquished", "Notes")
  
  # Store the table data in a data.frame
  df <- as.data.frame(table_html)
  
  # Append the data to the all-data data.frame
  games_missed_from_injury <- rbind(games_missed_from_injury, df)
  
  # Update the start value to scrape the next page
  start_value <- start_value + 25
}

## removing additional rows with no information
games_missed_from_injury = subset(games_missed_from_injury, Date != "Date")
## removing Acquired variable because it contains no information
games_missed_from_injury = subset(games_missed_from_injury, select = -Acquired)

library(stringr)

## removing the bullet in front of the plays name who was injured 
games_missed_from_injury$Relinquished <- str_remove(games_missed_from_injury$Relinquished, "â€¢ ")
## removing parenthesis after name (usually containing the players full name or their birthdate) to ensure that all names are formatted the same way
games_missed_from_injury$Relinquished <- sub("\\(.*\\)", "", games_missed_from_injury$Relinquished)
## removing the slashes after the name of the player who was injury (usually contains the players nickname(s)) to ensure that all names are formatted the same way
games_missed_from_injury$Relinquished <- sapply(strsplit(games_missed_from_injury$Relinquished, "/"), "[", 1)
## formatting 'Date' variable as a date in order to count the number of days since last game was played
games_missed_from_injury$Date <- as.Date(games_missed_from_injury$Date)

## adding year column in order to create unique id to merge tables
#games_missed_from_injury$Year = year(games_missed_from_injury$Date)


## splitting the relinquished column to have a first_name and last_name column
games_missed_from_injury$first_name <- gsub("^(\\S+)\\s.*$", "\\1", games_missed_from_injury$Relinquished)
games_missed_from_injury$last_name <- gsub("^\\S+\\s(.*)$", "\\1", games_missed_from_injury$Relinquished)

## removing suffixes to have the data structured the same way as those from fast_scraper_roster function within nflfastR
#games_missed_from_injury$last_name <- gsub("\\s.*", "", games_missed_from_injury$last_name)
games_missed_from_injury$last_name <- sapply(games_missed_from_injury$last_name, function(x) {
  if (grepl(" ", x)) {
    parts <- strsplit(x, " ")[[1]]
    if (parts[length(parts)] %in% c("Jr.", "Sr.","II" ,"III", "IV", "V")) {
      return(parts[length(parts) - 1])
    } else {
      return(parts[length(parts)])
    }
  } else {
    return(x)
  }
})
## adding season variable to merge with the table below (accounting for games played in the first few weeks of the new year as included in the previous season)
# Create a "season" variable based on the "Date" column
games_missed_from_injury$season <- format(games_missed_from_injury$Date, "%Y")

# Adjust the season values for the 2019 season
#games_missed_from_injury$season[games_missed_from_injury$Date < as.Date("2019-08-08")] <- as.character(as.numeric(format(games_missed_from_injury$Date[games_missed_from_injury$Date < as.Date("2019-08-08")], "%Y")) - 1)

# Adjust the season values for the 2020 season
games_missed_from_injury$season[games_missed_from_injury$Date >= as.Date("2019-06-27") & games_missed_from_injury$Date <= as.Date("2020-02-28")] <- "2019"

# Adjust the season values for the 2021 season
games_missed_from_injury$season[games_missed_from_injury$Date > as.Date("2020-05-08") & games_missed_from_injury$Date < as.Date("2021-02-28")] <- "2020"

# Adjust the season values for the 2021 season
games_missed_from_injury$season[games_missed_from_injury$Date > as.Date("2021-05-08") & games_missed_from_injury$Date < as.Date("2022-03-10")] <- "2021"

# Adjust the season values for the 2022 season
games_missed_from_injury$season[games_missed_from_injury$Date >= as.Date("2022-03-11")] <- "2022"


## adding team abbreviations in order to create a unique id to join the player_position table
nfl_teams <- data.frame(
  team_name = c("Cardinals", "Falcons", "Ravens", "Bills", "Panthers", "Bears", "Bengals", "Browns", "Cowboys", "Broncos", "Lions", "Packers", 
                "Texans", "Colts", "Jaguars", "Chiefs", "Raiders", "Chargers", "Rams", "Dolphins", "Vikings", "Patriots", "Saints", "Giants", 
                "Jets", "Eagles", "Steelers", "49ers", "Seahawks", "Buccaneers", "Titans", "Washington", "Redskins"),
  team_abbreviation = c("ARI", "ATL", "BAL", "BUF", "CAR", "CHI", "CIN", "CLE", "DAL", "DEN", "DET", "GB", "HOU", "IND", "JAX", "KC", 
                        "LV", "LAC", "LA", "MIA", "MIN", "NE", "NO", "NYG", "NYJ", "PHI", "PIT", "SF", "SEA", "TB", "TEN", "WAS", "WAS")
)

# Join the nfl_teams data with the injury_data on the team name
games_missed_from_injury <- merge(games_missed_from_injury, nfl_teams, by.x = "Team", by.y = "team_name")


## creation of unique id: 'player_id'
games_missed_from_injury$player_id <- paste0(games_missed_from_injury$season, "_", games_missed_from_injury$last_name, "_", games_missed_from_injury$team_abbreviation)

write_csv(games_missed_from_injury, 'games_missed_from_injury.csv')


```

```{r pulling_position_and_team_name_of_injured_player_who_missed_game}

library(nflfastR)
player_position = fast_scraper_roster(2019: 2022)

player_position = player_position[,c('season', 'team', 'position','depth_chart_position', 'jersey_number',
                                     'status', 'full_name', 'first_name', 'last_name', 'birth_date',
                                     'college', 'years_exp', 'week', 'game_type', 'football_name', 'entry_year')]

colnames(player_position) = c('season', 'team', 'position','depth_chart_position', 'jersey_number',
                                     'status', 'full_name', 'first_name', 'last_name', 'birth_date',
                                     'college', 'years_exp', 'week', 'game_type', 'football_name', 'entry_year')

## creation of unique id: 'player_id' for the player_position table
player_position$player_id <- paste0(player_position$season, "_", player_position$last_name, "_", player_position$team)
player_position <- distinct(player_position, player_id, .keep_all = TRUE)
write_csv(player_position, 'player_position_r.csv')
## had to make manual changes to certain players names (i.e., Vander Esch from one of the tables, Esch from another; DeValve in one table was Devalve in another)

```



```{r merging_player_position_with_games_missed_from_injury}

library(dplyr)

games_missed_from_injury = read_csv('Rmd_files/games_missed_from_injury.csv')
names(games_missed_from_injury)[8] <- "team"

# Create a new column 'area_of_injury' as NA
games_missed_from_injury$area_of_injury <- NA

# Extract the area of injury from the 'Notes' column and assign it to the 'area_of_injury' column
games_missed_from_injury$area_of_injury <- ifelse(is.na(games_missed_from_injury$area_of_injury),
                                                  str_extract(games_missed_from_injury$Notes, ".*(?= injury)"),
                                                  games_missed_from_injury$area_of_injury)

# Replace remaining NA values with original values from 'Notes'
games_missed_from_injury$area_of_injury <- ifelse(is.na(games_missed_from_injury$area_of_injury),
                                                  games_missed_from_injury$Notes,
                                                  games_missed_from_injury$area_of_injury)

# Remove parenthesis from the 'area_of_injury' column
games_missed_from_injury$area_of_injury <- gsub("\\s*\\([^\\)]+\\)", "", games_missed_from_injury$area_of_injury)


## table for the frequency of certain types of injuries that resulted from players missing games
injury_counts <- table(games_missed_from_injury$area_of_injury)
injury_counts_sorted <- sort(injury_counts, decreasing = TRUE)


# Group the injury data by player_id, season, team, and any other relevant columns to see the number of games missed in a season by a player
games_missed_from_injury_agg <- games_missed_from_injury %>%
  group_by(player_id, season, team) %>%
  summarize(games_missed = n())
head(games_missed_from_injury_agg,20)

## updated csv file from manual changes to player names to match the 
player_position = read_csv('Rmd_files/player_position_Rmd.csv')
player_position <- distinct(player_position, player_id, .keep_all = TRUE)


# Merge the two tables by player ID, position, and team
merged_table_injury_by_position <- inner_join(games_missed_from_injury, player_position, by = "player_id")
merged_table_injury_by_position <- merged_table_injury_by_position %>%
  select(-ends_with(".y")) %>%  # Remove the ".y" variables
  rename_with(~gsub("\\.x$", "", .), ends_with(".x"))  # Rename the ".x" variables

merged_table_injury_by_position <- merged_table_injury_by_position %>%
  select(-player_id, player_id)
head(merged_table_injury_by_position,20)


merged_table_num_injuries_by_player_by_season = inner_join(games_missed_from_injury_agg, player_position, by = 'player_id')
head(merged_table_num_injuries_by_player_by_season,20)




# Merge the aggregated injury data with the player position data
#player_data <- left_join(games_missed_from_injury_agg,player_position ,by = "player_id")
## provides the number of injuries that a player suffered associated with the player_id of the individual
## results in 1423 observations, 44 missing observations, total games missed in the table: 2621

#player_data <- dplyr::full_join(games_missed_from_injury_agg,player_position ,by = "player_id")

#player_data <- merge(games_missed_from_injury_agg,player_position ,by = "player_id")
## results in 1378 observations, NO missing observations, total games missed in the table: 2566


#merged_data <- left_join(games_missed_from_injury, player_position, by = "player_id")
## results in 55 missing obs, 2621 observations

#colSums(is.na(merged_table_injury_by_position))
write_csv(merged_table_injury_by_position, "merged_table_injury_by_position.csv")
#head(merged_table_injury_by_position,20)
#colSums(is.na(merged_table_num_injuries_by_player_by_season))
write_csv(merged_table_num_injuries_by_player_by_season, "merged_table_num_injuries_by_player_by_season.csv")
#head(merged_table_injury_by_position,20)
```


```{r gtsummary}
df1 = read_csv("Rmd_files/df_master_schedule_injury_surface_2019_23_weather_distance_modeling.csv")
glimpse(df1)

library(tidyverse)
df2 = read_csv("Rmd_files/df_master_schedule_injury_surface_2019_23_weather_distance_days_since_last_game_modeling_neutral_sites.csv")

df3 = read_csv("merged_table_injury_by_position.csv")
#install.packages('gtsummary')
library(gtsummary)
df1 %>% unique()

df1$surface_type %>% unique()
table(df1$surface_type)


injury_test2 = read_csv("injury_test.csv")
injury_test2$surface_type[injury_test2$surface_type=='Hybrid'] = 'Turf'

injury_test2$stadium = relevel(as.factor(injury_test2$stadium), ref = "Levi's Stadium")
injury_test2$day = relevel(as.factor(injury_test2$day), ref = "Sun")
injury_test2$dome = relevel(as.factor(injury_test2$dome), ref = "TRUE")

poisson1 = glm(data = injury_test2, formula = num_injuries ~ num_plays + surface_type + distance_miles + HOME_day_since_last_game + AWAY_day_since_last_game + Avg_Feels_Like + Avg_Percipitation_Prob_Percent + dome + Avg_Humidity_Percent+  contact_noncontact + injury_area + player_role + game_half + ydstogo ,family = 'poisson')


injury_test2 = injury_test2 %>% 
  tidyr::separate(col = injured_team, into = c('injured_team', 'inj_player_num'))

injury_test3 = injury_test2 %>% group_by(game_id, injured_team) %>% summarise(
  num_injuries = num_injuries,
  surface_type = surface_type,
  dome = dome,
  num_inj_team = n(),
  Avg_Percipitation_Prob_Percent = Avg_Percipitation_Prob_Percent,
  Avg_Feels_Like = Avg_Feels_Like,
  Away_abbr = Away_abbr,
  Home_abbr = str_sub(game_id, start = -3, end = -1) %>% str_replace(pattern = '_', replacement = '')
) %>% ungroup() %>% unique()

data_frame_with_counters <- injury_test3 %>%
  mutate(Home_inj_team = ifelse(injured_team == Home_abbr, num_inj_team, 0),
         Away_inj_team = ifelse(injured_team == Away_abbr, num_inj_team, 0))

team_injury_summary <- data_frame_with_counters %>%
  group_by(injured_team) %>%
  summarise(Home_injuries = sum(Home_inj_team),
            Away_injuries = sum(Away_inj_team),
            Total_injuries = Home_injuries + Away_injuries
            ) %>%
  ungroup()

write_csv(team_injury_summary, "Rmd_files/injury_sum_by_team_home_away.csv")

#newdf = team_injury_summary[,c(team_injury_summary$injured_team, team_injury_summary$Home_injuries, team_injury_summary$Away_injuries, team_injury_summary$Total_injuries)]
#table(team_injury_summary$inj_team, team_injury_summary$Home_injuries, team_injury_summary$Away_injuries, team_injury_summary$Total_num_injuries)

poisson1 = glm(data = injury_test2, formula = num_injuries ~ num_plays + surface_type + distance_miles + HOME_day_since_last_game + AWAY_day_since_last_game + Avg_Feels_Like + Avg_Percipitation_Prob_Percent + dome + Avg_Humidity_Percent+  Contact_NonContact + injury_area + player_role + game_half + ydstogo ,family = 'poisson')

poisson2 = glm(data=injury_test3, family = 'poisson', formula = num_inj_team ~ inj_team + surface_type + dome + Avg_Percipitation_Prob_Percent + Avg_Feels_Like)
summary(poisson2)
gtsummary::tbl_regression(poisson2)

df2 %>% dplyr::filter(surface_type == 'Turf') %>% pull(num_injuries) %>% hist()
df2 %>% dplyr::filter(surface_type == 'Grass') %>% pull(num_injuries) %>% hist()

df2 %>% dplyr::filter(distance_miles >= 2000) %>% filter(surface_type == "Turf") %>% filter(num_injuries >= 2) %>% pull(num_injuries) %>% hist(breaks = 8)
df2 %>% dplyr::filter(distance_miles >= 2000) %>% filter(surface_type == "Grass") %>% filter(num_injuries >= 2) %>% pull(num_injuries) %>% hist(breaks = 8)


df_dt = injury_test2 %>% dplyr::select(c(num_injuries, num_plays , surface_type , distance_miles , HOME_day_since_last_game , AWAY_day_since_last_game , Avg_Feels_Like , Avg_Percipitation_Prob_Percent , dome, Avg_Humidity_Percent, Contact_NonContact, injury_area, player_role, game_half, ydstogo)) 

train_rows = sample(1:nrow(df_dt), size = ceiling(0.8*nrow(df_dt)))

train_data = df_dt[train_rows, ]
test_data = df_dt[-train_rows, ]

library(caret)
ctrl = trainControl(method = 'repeatedcv', repeats = 5)

decision_tree_fit = train(x = train_data %>% select(-num_injuries), y = train_data$num_injuries, method = 'rpart', tuneLength = 10)

injury_test2 %>% dplyr::filter(dome == TRUE) %>% pull(surface_type) %>% table() %>% prop.table()
df2 %>% dplyr::filter(surface_type == 'Grass') %>% pull(num_injuries) %>% table() %>% prop.table()

gtsummary::tbl_regression(poisson1)
summary(poisson1)

  
devtools::install_github(repo = "ryurko/nflscrapR")  
```


```{r test_position}
df2 = read_csv("Rmd_files/df_master_schedule_injury_surface_2019_23_weather_distance_days_since_last_game_modeling_neutral_sites.csv")
df2_players_sep = df2 %>% separate_rows(injured_players, sep = ",\\s*")
df2_players_sep = df2_players_sep %>% 
  tidyr::separate(col = injured_players, into = c('injured_first_name', 'injured_last_name'))



injury_test2 = read_csv("injury_test_neutral_sites.csv")
injury_test2$surface_type[injury_test2$surface_type=='Hybrid'] = 'Turf'

injury_test2$stadium = relevel(as.factor(injury_test2$stadium), ref = "Levi's Stadium")
injury_test2$day = relevel(as.factor(injury_test2$day), ref = "Sun")
injury_test2$dome = relevel(as.factor(injury_test2$dome), ref = "TRUE")

poisson1 = glm(data = injury_test2, formula = num_injuries ~ num_plays + surface_type + distance_miles + HOME_day_since_last_game + AWAY_day_since_last_game + Avg_Feels_Like + Avg_Percipitation_Prob_Percent + dome + Avg_Humidity_Percent+  contact_noncontact + injury_area + player_role + game_half + ydstogo ,family = 'poisson')


injury_test2 = injury_test2 %>% 
  tidyr::separate(col = injured_team, into = c('injured_team', 'injured_player_num'))

injury_test2 = injury_test2 %>% 
  tidyr::separate(col = injured_players, into = c('injured_first_name', 'injured_last_name'))



injury_test2$player_id = paste0(injury_test2$season,"_", injury_test2$injured_team, "_", injury_test2$injured_player_num, "_", injury_test2$injured_last_name)

rosters = nflreadr::load_rosters(2019:2022)
rosters$player_id = paste0(rosters$season, "_", rosters$team, "_", rosters$jersey_number, "_", rosters$last_name)
rosters = rosters %>% filter(season == 2019)

injury_test2_sorted <- injury_test2 %>% arrange(player_id)
rosters_sorted <- rosters %>% arrange(player_id)

position_injury_player <- merge(injury_test2_sorted, rosters_sorted, by = "player_id")

#position_injury_player = merge(injury_test2, rosters, by = "player_id", )
write_csv(position_injury_player, "Rmd_files/position_injury_player_download.csv")

#write_csv(team_injury_summary, "Rmd_files/injury_sum_by_team_home_away.csv")

```


```{r visual_Total_Injuries_by_Team}
##INTERACTIVE CODE
sum_injury = read_csv("Rmd_files/injury_sum_by_team_home_away.csv")
library(ggplot2)

# reshape data to long format
injuries_data_long <- sum_injury %>%
  tidyr::gather(key = "injury_type", value = "count", Home_injuries, Away_injuries) %>%
  mutate(injury_type = ifelse(injury_type == "Home_injuries", "Home", "Away"))

# create stacked bar chart
p <- ggplot(injuries_data_long, aes(x = injured_team, y = count, fill = injury_type,
                                    text = paste("Team: ", injured_team, "<br>",
                                                 "Home injuries: ", ifelse(injury_type == "Home", count, 0), "<br>",
                                                 "Away injuries: ", ifelse(injury_type == "Away", count, 0), "<br>",
                                                 "Total injuries: ", Total_injuries))) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("#619CFF", "#FF7942"), name = "Injury type",
                    labels = c("Home", "Away")) +
  labs(title = "Total Injuries by Team", x = "Team", y = "Total Injuries") +
  theme(axis.text.x = element_text(size = 12, angle = 90, hjust = 1),
        plot.title = element_text(size = 20),
        legend.title = element_text(size = 14),
        axis.title.x = element_blank(),
        axis.title.y = element_text(size = 14))

# convert to plotly object and add tooltip settings
p <- ggplotly(p, tooltip = c("text"))
p <- p %>% layout(hovermode = "closest")
p


## NON INTERACTIVE CODE FOR POWER BI
# create stacked bar chart
ggplot(injuries_data_long, aes(x = injured_team, y = count, fill = injury_type)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("#619CFF", "#FF7942"), name = "Injury type",
                    labels = c("Home", "Away")) +
  labs(title = "Total Injuries by Team", x = "Team", y = "Total Injuries") + 
  theme(axis.text.x = element_text(size = 12, angle = 90, hjust = 1),
        plot.title = element_text(size = 20),
        legend.title = element_text(size = 14),
        axis.title.x = element_blank(),
        axis.title.y = element_text(size = 14))
```


```{r visualization_Away_Team_Number_of_Injuries_Based_on_Miles_Traveled}
df10 = read_csv("Rmd_files/position_injury_player_updated.csv")
library(RColorBrewer)

# create new columns for home and away injuries
distance_data_filtered <- df10 %>%
  mutate(Home_injuries = ifelse(injured_team != Away_abbr, 1, 0),
         Away_injuries = ifelse(injured_team == Away_abbr, 1, 0))

distance_data_filtered <- distance_data_filtered %>%
  filter(injured_team == Away_abbr)

# count number of observations in each distance bucket by injured team
distance_counts <- distance_data_filtered %>%
  group_by(injured_team, distance_bucket = cut(distance_miles, breaks = seq(0, 4000, 500), right = FALSE)) %>%
  summarise(n = n(), total_home_injuries = sum(Home_injuries), total_away_injuries = sum(Away_injuries)) %>%
  ungroup()

my_palette <- colorRampPalette(c("#8dd3c7", "#ffffb3", "#bebada", "#fb8072", "#80b1d3", "#fdb462", "#b3de69", "#fccde5", "#d9d9d9", "#bc80bd", "#ccebc5", "#ffed6f", "#1f78b4", "#33a02c", "#e31a1c", "#ff7f00", "#cab2d6", "#6a3d9a", "#a6cee3", "#b2df8a", "#fb9a99", "#fdbf6f", "#ffff99", "#8dd3c7", "#ffffb3", "#bebada", "#fb8072", "#80b1d3", "#fdb462", "#b3de69"))

# create stacked bar chart of distance traveled by injured team
p <- ggplot(distance_counts, aes(x = distance_bucket, y = n, fill = injured_team, 
                                 text = paste("Team: ", injured_team, "<br>",
                                              "Distance: ", gsub("[\\[\\],]", "", distance_bucket), "<br>",
                                              "Total Away Injuries: ", total_away_injuries))) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = my_palette(30)) +
  labs(title = "Distance Traveled by Injured Teams", x = "Distance Bucket", y = "Count") +
  scale_x_discrete(labels = c("[0, 500]", "(500, 1000]", "(1000, 1500]", "(1500, 2000]", "(2000, 2500]", "(2500, 3000]", "(3000, 3500]", "(3500, 4000]"))

library(plotly)
# convert to plotly object and add tooltip settings
p = ggplotly(p, tooltip = c("text"))
p = p %>% layout(hovermode = "closest")
p
```

```{r non_interactive_stadium_injuries_home_away}



## NON INTERACTIVE
df10 <- read_csv("Rmd_files/position_injury_player_updated.csv")

# create new columns for home and away injuries
df10 <- df10 %>%
  mutate(home_injuries = if_else(injured_team == Home_abbr, 1, 0),
         away_injuries = if_else(injured_team != Away_abbr, 1, 0))

# group by stadium and summarize counts of home and away injuries
stadium_counts <- df10 %>%
  group_by(stadium) %>%
  summarize(home_injuries = sum(home_injuries),
            away_injuries = sum(away_injuries))

# convert data to long format and create injury_type column
stadium_counts_long <- stadium_counts %>%
  gather(key = "injury_type", value = "count", home_injuries, away_injuries) %>%
  mutate(injury_type = if_else(injury_type == "home_injuries", "Home", "Away"))

# create stacked bar chart
ggplot(stadium_counts_long, aes(x = stadium, y = count, fill = injury_type)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("#619CFF", "#FF7942"), name = "Injury type",
                    labels = c("Home", "Away")) +
  labs(title = "Injuries by Stadium", x = "Stadium", y = "Count") +
  theme(axis.text.x = element_text(size = 12, angle = 90, hjust = 1),
        plot.title = element_text(size = 20),
        legend.title = element_text(size = 14),
        axis.title.x = element_blank(),
        axis.title.y = element_text(size = 14))

```

```{r interactive_stadium_injuries_home_away}

library(tidyverse)
library(plotly)

# read in data
df10 <- read_csv("Rmd_files/position_injury_player_updated.csv")

# create new columns for home and away injuries
df10 <- df10 %>%
  mutate(home_injuries = if_else(injured_team == Home_abbr, 1, 0),
         away_injuries = if_else(injured_team == Away_abbr, 1, 0))

# group by stadium and summarize counts of home and away injuries
stadium_counts <- df10 %>%
  group_by(stadium) %>%
  summarize(home_injuries = sum(home_injuries),
            away_injuries = sum(away_injuries),
            total_injuries = sum(home_injuries) + sum(away_injuries))

# calculate total injuries across all stadiums
total_injuries <- sum(stadium_counts$total_injuries)

# convert data to long format and create injury_type column
stadium_counts_long <- stadium_counts %>%
  gather(key = "injury_type", value = "count", home_injuries, away_injuries) %>%
  mutate(injury_type = if_else(injury_type == "home_injuries", "Home", "Away"),
         percent_total = scales::percent(count/total_injuries),
         total_count = sum(count))

# calculate total injuries per stadium
stadium_totals <- stadium_counts_long %>%
  group_by(stadium) %>%
  summarise(total_injuries = sum(count))

# merge stadium_totals with stadium_counts_long
stadium_counts_long <- stadium_counts_long %>%
  left_join(stadium_totals)


# create stacked bar chart with plotly
p <- ggplot(stadium_counts_long, aes(x = stadium, y = count, fill = injury_type,
                                     text = paste("Stadium: ", stadium, "<br>",
                                                  if_else(injury_type == "Home", 
                                                          paste("Home injuries: ", count, "<br>"), ""),
                                                  if_else(injury_type == "Away",
                                                          paste("Away injuries: ", count, "<br>"), ""),
                                                  paste("Percent of total stadium injuries: ", percent_total, "<br>"),
                                                  paste("Total injuries Per Stadium: ", stadium_totals$total_injuries, "<br>")
                                                  ))) +
  geom_bar(stat = "identity", position = "stack") +
  scale_fill_manual(values = c("#619CFF", "#FF7942"), name = "Injury type",
                    labels = c("Home", "Away")) +
  labs(title = "Injuries by Stadium", x = "Stadium", y = "Count") +
  theme(axis.text.x = element_text(size = 12, angle = 90, hjust = 1),
        plot.title = element_text(size = 20),
        legend.title = element_text(size = 14),
        axis.title.x = element_blank(),
        axis.title.y = element_text(size = 14))

# convert to plotly object and add tooltip settings
p <- ggplotly(p, tooltip = c("text"))
p <- p %>% layout(hovermode = "closest")

p

```


```{r gtsummary testing}
pos_inj_complete = read_csv("Rmd_files/position_injury_player_updated.csv")

pos_inj_complete = pos_inj_complete %>% mutate(dome = ifelse(dome, "TRUE", "FALSE"))

pos_inj_complete$stadium = relevel(as.factor(pos_inj_complete$stadium), ref = "State Farm Stadium")
pos_inj_complete$day = relevel(as.factor(pos_inj_complete$day), ref = "Sun")
pos_inj_complete$dome = relevel(as.factor(pos_inj_complete$dome), ref = "TRUE")
pos_inj_complete$injured_team = relevel(as.factor(pos_inj_complete$injured_team), ref = "SF")


position_injury_pois1 = glm(data = pos_inj_complete, formula = num_injuries ~ num_plays + surface_type + distance_miles + injured_team +  injury_area + stadium + dome + game_half + position + contact_noncontact + day + player_role ,family = 'poisson')

gtsummary::tbl_regression(position_injury_pois1)
summary(position_injury_pois1)


injury_player_pos_dt = read_csv("Rmd_files/position_injury_player_updated_dt.csv")
complete_rows = complete.cases(injury_player_pos_dt)
df_complete = injury_player_pos_dt[complete_rows,]
df_dt = df_complete %>% dplyr::select(c(num_injuries, num_plays, distance_miles , game_half , ydstogo, Avg_Temp, Avg_Humidity_Percent))

train_rows = sample(1:nrow(df_dt), size = ceiling(0.8*nrow(df_dt)))

train_data = df_dt[train_rows, ]
test_data = df_dt[-train_rows, ]

library(caret)
ctrl = trainControl(method = 'repeatedcv', repeats = 5)

decision_tree_fit = train(x = train_data %>% select(-num_injuries), y = train_data$num_injuries, method = 'rpart', tuneLength = 10)


```
